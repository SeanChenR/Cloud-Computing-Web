import time
import requests
import configparser
import streamlit as st
from bs4 import BeautifulSoup
from datetime import datetime as dt
from qdrant_client import QdrantClient
from streamlit_extras.grid import grid
from streamlit_option_menu import option_menu
from langchain_qdrant import Qdrant
from langchain.chains import ConversationChain
from langchain_core.prompts.prompt import PromptTemplate
from langchain_community.document_loaders import PyPDFLoader
from langchain.text_splitter import RecursiveCharacterTextSplitter

from blob_list import get_blob_list
from vision import recognizer_azure
from translator import translator_azure
from storage_upload import upload_to_azure_storage
from TWSC_embedding import get_embeddings_model
from llm import chat_ffm, memory

config = configparser.ConfigParser()
config.read('config.ini')

API_KEY = config['embedding']['API_KEY']
API_URL = config['embedding']['API_URL']
MODEL_NAME = config['embedding']['MODEL_NAME']

embeddings_model = get_embeddings_model(API_URL, API_KEY, MODEL_NAME)

qdrant_url = config['qdrant']['url']
qdrant_port = config['qdrant']['port']
qdrant_api_key = config['qdrant']['api_key']

background_color = "green"

language = {
    "ç¹é«”ä¸­æ–‡ (zh-hant)" : "zh-hant",
    "è‹±æ–‡ (en)" : "en",
    "æ—¥æ–‡ (ja)" : "ja",
    "éŸ“æ–‡ (ko)" : "ko",
    "è¥¿ç­ç‰™æ–‡ (es)" : "es",
}

def rag(query, rag_result):
    prompt_template = """ä½ æ˜¯ä¸€ä½æ¨‚æ–¼åŠ©äººçš„å°å¹«æ‰‹ï¼Œè«‹çš†ä»¥ç¹é«”ä¸­æ–‡å›ç­”å•é¡Œï¼Œä¸¦åƒ…æ ¹æ“š<text></text>é€™å€‹html tagä¸­çš„åƒè€ƒè³‡æ–™å›ç­”å•é¡Œï¼Œä¸çŸ¥é“å°±èªªä¸çŸ¥é“ï¼Œä¸æº–ä¾ç…§è‡ªå·±çš„æƒ³æ³•å›ç­”ã€‚
                            ç„¶å¾Œè«‹ä»¥ä¸€å€‹å°ˆæ¥­äººå£«æˆ–ç›¸é—œå–®ä½å·¥ä½œäººå“¡çš„è§’åº¦å›ç­”å•é¡Œï¼Œè‹¥è³‡æ–™æœ‰å‡ºè™•è«‹è¨»æ˜å‡ºè™•ã€‚
                            <text>{context}</text>
                            å•é¡Œï¼š{question}"""
    prompt = PromptTemplate(input_variables=["context", "question"], template=prompt_template)
    llm = prompt | chat_ffm
    result = llm.invoke({"context":rag_result, "question":query})
    return result.content

def single_chat(query):
    prompt_template = """ä½ æ˜¯ä¸€ä½å¾—åŠ›AIåŠ©æ‰‹ï¼Œå°ä»»ä½•å•é¡Œç¸½èƒ½å›æ‡‰æœ‰å¹«åŠ©çš„ç­”æ¡ˆã€‚
                            ä½¿ç”¨è€…è¼¸å…¥å…§å®¹ï¼š{question}"""
    prompt = PromptTemplate(input_variables=["question"], template=prompt_template)
    llm = prompt | chat_ffm
    result = llm.invoke({"question":query})
    return result.content

def memory_chat(query):
    conversation_with_summary = ConversationChain(
        llm=chat_ffm,
        memory=memory,
        verbose=True,
    )
    
    ans = conversation_with_summary.predict(input=query)
    return ans

def summary(query):
    prompt_template = "I need to summarize the article. No prefix! The article is as follows: {article}"
    prompt = PromptTemplate(input_variables=["article"], template=prompt_template)
    llm = prompt | chat_ffm
    result = llm.invoke({"article":query})
    return result.content

def typewriter(text: str, speed: int):
    tokens = text.split()
    container = st.empty()
    for index in range(len(tokens) + 1):
        curr_full_text = " ".join(tokens[:index])
        container.markdown(curr_full_text)
        time.sleep(1 / speed)

def txt_contents(url):
    response = requests.get(url)
    response.encoding = "utf-8"
    soup = BeautifulSoup(response.text, "html.parser")
    return soup.prettify()

with st.sidebar:
    selected = option_menu(
    menu_title="Main Menu",
    options=["Home", "PDF QA", "Translate", "Summarize", "Chat Bot", "Image Vision"],
    icons=["house-fill", "filetype-pdf", "translate", "feather", "robot", "cpu"],
    menu_icon="list-ul",
    default_index=0
)

client = QdrantClient(url=qdrant_url,
                        port=qdrant_port,
                        api_key=qdrant_api_key)

if selected == "Home":
    st.header(':rainbow[é›²ç«¯é‹ç®—æœå‹™_ç¬¬å…­çµ„_æœŸæœ«å°ˆæ¡ˆ]')

    st.subheader("ğŸ‘ˆ å¯ä»¥é€éå·¦å´åˆ—è¡¨é¸æ“‡æœå‹™")

    st.markdown("### Home")

    st.code(
    """
    ğŸ”§ å·¥å…·èˆ‡é¸å–®æœå‹™ä»‹ç´¹
    ğŸ”— ä¸²æ¥å°æ™ºé›²ã€Qdrant Cloud
    â˜ï¸ Azure - Translate Computer Vision Storage 
    """
    )

    st.markdown("### PDF QA")

    st.code(
    """
    ğŸ” ä¸Šå‚³PDFæª”è‡³è³‡æ–™åº«
    ğŸ“‘ é¸æ“‡è³‡æ–™åº«çš„PDFæª”ï¼Œä¸¦é¡¯ç¤ºå…§å®¹
    ğŸ’¡ æ ¹æ“šPDFæª”çš„å…§å®¹é€²è¡Œæå•ï¼ŒAIæœƒæ ¹æ“šPDFæª”å›ç­”å•é¡Œ
    """
    )

    st.markdown("### Translate")

    st.code(
    """
    ğŸ‡¹ğŸ‡¼ğŸ‡¯ğŸ‡µğŸ‡°ğŸ‡·ğŸ‡ºğŸ‡¸ğŸ‡ªğŸ‡¸ äº”ç¨®åœ‹éš›èªè¨€å¯é¸æ“‡
    """
    )

    st.markdown("### Summarize")

    st.code(
    """
    ğŸ“ ä¸Šå‚³TXTæª”è‡³è³‡æ–™åº«
    ğŸ“° è¼¸å…¥æ–‡ç« æˆ–æ–°èï¼ŒAIæœƒå°å…¶é€²è¡Œæ‘˜è¦
    ğŸ’» é¸æ“‡è³‡æ–™åº«çš„TXTæª”ï¼Œä¸¦è®“AIé€²è¡Œæ‘˜è¦
    """
    )

    st.markdown("### Chat Bot")

    st.code(
    """
    ğŸ”‘ åƒChatGPTä½¿ç”¨å³å¯
    """
    )

    st.markdown("### Image Vision")

    st.code(
    """
    ğŸ¶ ä¸Šå‚³jpg/pngæª”è‡³è³‡æ–™åº«ï¼Œä¸¦å°å…¶é€²è¡Œè¾¨è­˜
    ğŸ® é¸æ“‡è³‡æ–™åº«çš„åœ–ç‰‡æª”ï¼Œä¸¦è®“AIå°å…¶é€²è¡Œè¾¨è­˜
    """
    )

if selected == "PDF QA":
    st.header(':rainbow[é›²ç«¯é‹ç®—æœå‹™_ç¬¬å…­çµ„_PDF QA]')

    selected_pdf = option_menu(
        menu_title=None,
        options=["PDF File", "PDF View", "Upload"],
        icons=["file-pdf-fill", "printer-fill", "cloud-upload-fill"],
        menu_icon="cast",
        default_index=0,
        orientation="horizontal",
        styles={
            "container": {"padding": "0!important", "background-color": background_color},
            "icon": {"color": "orange", "font-size": "25px"},
            "nav-link": {
                "font-size": "25px",
                "text-align": "left",
                "margin": "0px",
                "--hover-color": "#eee",
            },
            "nav-link-selected": {"background-color": "#6F00D2"},
        },
    )

    if selected_pdf == "PDF View":
        blob_list = get_blob_list("pdf")
        pdf_file = st.selectbox("è«‹é¸æ“‡pdfæª”", blob_list)
        url = f"https://storage09170285.blob.core.windows.net/image/{pdf_file}"

        if st.button("Print the contents of PDF", use_container_width=True):
            loader = PyPDFLoader(url)
            docs = loader.load()
            for doc in docs:
                st.write(doc.page_content)

    if selected_pdf == "PDF File":
        blob_list = get_blob_list("pdf")
        pdf_grid = grid(1,1,1, vertical_align="center")
        pdf_file = pdf_grid.selectbox("è«‹é¸æ“‡pdfæª”", blob_list)
        query = pdf_grid.text_input("è«‹è¼¸å…¥é—œæ–¼æ­¤pdfæª”çš„ç›¸é—œå•é¡Œ")
        if st.button("Submit the question", use_container_width=True):
            with st.spinner('Searching from Qdrant Cloud...'):
                search_result = client.search(
                    collection_name=pdf_file,
                    query_vector=embeddings_model.embed_query(query),
                    limit=1,
                    with_payload=True,
                    with_vectors=False,
                )
                if len(search_result) == 0:
                    with st.chat_message("assistant"):
                        st.markdown("No Results Found")
                else:
                    llm_result = rag(query, search_result[0].payload['page_content'])
                    with st.chat_message("assistant"):
                        st.markdown(llm_result)

    if selected_pdf == "Upload":
        uploaded_file = st.file_uploader('Choose a PDF file', type="pdf")

        if uploaded_file is not None:
            collection_name = uploaded_file.name
            url = f"https://storage09170285.blob.core.windows.net/image/{uploaded_file.name}"
            if st.button("Upload to Azure Storage", use_container_width=True):
                try:
                    with st.spinner('Uploading to Azure...'):
                        upload_to_azure_storage(uploaded_file)
                        st.success("File uploaded to Azure Storage!", icon="âœ…")
                except:
                    st.error("Error uploading file to Azure Storage, because the file is already exist!")
                
                finally:
                    with st.spinner('Uploading to Qdrant Cloud...'):
                        loader = PyPDFLoader(url)

                        docs = loader.load()

                        splitter = RecursiveCharacterTextSplitter(    
                            chunk_size=500,
                            chunk_overlap=100)

                        chunks = splitter.split_documents(docs)

                        qdrant = Qdrant.from_documents(
                            chunks,
                            embeddings_model,
                            url=qdrant_url,
                            port=qdrant_port,
                            api_key=qdrant_api_key,
                            collection_name=collection_name,
                            force_recreate=True,
                        )
                        st.success("It is successfully imported them into the Qdrant database.", icon="âœ…")

if selected == "Translate":
    st.header(':rainbow[é›²ç«¯é‹ç®—æœå‹™_ç¬¬å…­çµ„_Translate]')
    my_grid = grid(2, 2, 1, vertical_align="bottom")
    # row1
    Input = my_grid.selectbox("é¸æ“‡è¼¸å…¥èªè¨€ï¼š", ["ç¹é«”ä¸­æ–‡ (zh-hant)", "è‹±æ–‡ (en)", "æ—¥æ–‡ (ja)", "éŸ“æ–‡ (ko)", "è¥¿ç­ç‰™æ–‡ (es)"])
    Output = my_grid.selectbox("é¸æ“‡è¼¸å‡ºèªè¨€ï¼š", ["è‹±æ–‡ (en)", "ç¹é«”ä¸­æ–‡ (zh-hant)", "æ—¥æ–‡ (ja)", "éŸ“æ–‡ (ko)", "è¥¿ç­ç‰™æ–‡ (es)"])
    # row2
    text_area_guide = f"è«‹ç”¨{Input}è¼¸å…¥æ¬²ç¿»è­¯çš„æ–‡å­—ï¼š"
    if language[Input] == "zh-hant":
        text_area_guide_en = "ä½ å¥½ï¼"
    elif language[Input] == "en":
        text_area_guide_en = "Hello !"
    elif language[Input] == "ja":
        text_area_guide_en = "ã“ã‚“ã«ã¡ã¯ï¼"
    elif language[Input] == "ko":
        text_area_guide_en = "ì•ˆë…•í•˜ì„¸ìš”ï¼"
    elif language[Input] == "es":
        text_area_guide_en = "Hola !"
    text_area_input = my_grid.text_area(text_area_guide, text_area_guide_en, height=40)
    if "default" not in st.session_state:
        st.session_state["default"] = ""
    my_area = my_grid.text_area("ç¿»è­¯çµæœï¼š", value=st.session_state["default"], height=40)
    #row3
    if my_grid.button("Translate", use_container_width=True, help="Press the Bottom to Translate"):
        with st.spinner('Translating...'):
            translate_result = translator_azure(language[Input], language[Output], text_area_input)
            st.session_state["default"] = translate_result
            st.rerun()

if selected == "Summarize":
    st.header(':rainbow[é›²ç«¯é‹ç®—æœå‹™_ç¬¬å…­çµ„_Summarize]')

    selected_summary = option_menu(
        menu_title=None,
        options=["TXT File", "Text Input", "Upload"],
        icons=["eye-fill", "chat-text", "cloud-upload-fill"],
        menu_icon="cast",
        default_index=0,
        orientation="horizontal",
        styles={
            "container": {"padding": "0!important", "background-color": background_color},
            "icon": {"color": "orange", "font-size": "25px"},
            "nav-link": {
                "font-size": "25px",
                "text-align": "left",
                "margin": "0px",
                "--hover-color": "#eee",
            },
            "nav-link-selected": {"background-color": "#6F00D2"},
        },
    )

    if selected_summary == "TXT File":
        blob_list = get_blob_list("txt")
        txt_grid = grid(1,[1,1],1, vertical_align="center")
        txt_file = txt_grid.selectbox("è«‹é¸æ“‡æ–‡å­—æª”", blob_list)
        url = f"https://storage09170285.blob.core.windows.net/image/{txt_file}"
        contents = txt_contents(url)
        txt_grid.text_area("The contents of the txt fileï¼š", value=contents, height=300)
        if "default_file" not in st.session_state:
            st.session_state["default_file"] = ""
        txt_grid.text_area("Summary Resultï¼š", value=st.session_state["default_file"], height=300)

        if txt_grid.button("Go Summary", use_container_width=True):
            with st.spinner('Reading and Summarzing...'):
                summary_result = summary(contents)
                st.session_state["default_file"] = summary_result
                st.rerun()

    if selected_summary == "Upload":
        uploaded_file = st.file_uploader('Choose a TXT file', type="txt")

        if uploaded_file is not None:
            url = f"https://storage09170285.blob.core.windows.net/image/{uploaded_file.name}"

            summary_grid = grid([1,1], 1, 1, vertical_align="bottom")
            if "default_txt" not in st.session_state:
                st.session_state["default_txt"] = ""
            summary_grid.text_area("The contents of the uploaded fileï¼š", value=st.session_state["default_txt"], height=300)
            if "default_summary" not in st.session_state:
                st.session_state["default_summary"] = ""
            summary_grid.text_area("Summary Resultï¼š", value=st.session_state["default_summary"], height=300)

            if st.button("Upload & Summarize", use_container_width=True):
                try:
                    with st.spinner('Uploading...'):
                        upload_to_azure_storage(uploaded_file)
                        st.success("File uploaded to Azure Storage!", icon="âœ…")
                except:
                    st.error("Error uploading file to Azure Storage, because the file is already exist!")

                finally:
                    with st.spinner('Summarzing...'):
                        time.sleep(5)
                        contents = txt_contents(url)
                        st.session_state["default_txt"] = contents
                        summary_result = summary(contents)
                        st.session_state['default_summary'] = summary_result
                        st.spinner('Reading and Summarzing...')
                        st.rerun()

    article = """
è¼é”ï¼ˆNVIDIAï¼‰åŸ·è¡Œé•·é»ƒä»å‹³æ–¼6æœˆ2æ—¥åœ¨å°å¤§é«”è‚²é¤¨é–‹è¬›ï¼Œæ‰“éŸ¿2024å¹´å°åŒ—åœ‹éš›é›»è…¦å±•ï¼ˆCOMPUTEXï¼‰çš„ç¬¬ä¸€æ§ã€‚è©²å ´æ¼”èªªè¬çœ¾çŸšç›®ï¼ŒåŒ…å«å»£é”è‘£äº‹é•·æ—ç™¾é‡Œã€è¯ç™¼ç§‘åŸ·è¡Œé•·è”¡åŠ›è¡Œå’Œç¾è¶…å¾®ï¼ˆSupermicroï¼‰è‘£äº‹é•·æ¢è¦‹å¾Œç­‰ç§‘æŠ€å¤§è€çš†åˆ°å ´å‡ºå¸­ã€‚ã€Œ3å…†ç¾å…ƒç”¢å€¼çš„ITç”¢æ¥­ï¼Œæœªä¾†å°‡æœƒå‚¬å‡ºé«˜é”100å…†ç¾å…ƒçš„ç”¢æ¥­é©å‘½ã€‚ã€é»ƒä»å‹³å†åº¦åŒ–èº«æœ€å¼·AIæ¨éŠ·å“¡ï¼Œé™¤å®£ä½ˆAIæ¨¡å‹æ¨è«–æœå‹™ç”¢å“ã€ŒNVIDIA NIMã€ï¼ŒåŒæ™‚æå‡ºå…¨æ–°æ¦‚å¿µæ•¸ä½äººé¡ï¼ˆDigital Humanï¼‰ï¼Œå¤§ç§€åŒ…å«3Dæ¨¡æ“¬å’Œå…‰ç·šè¿½è¹¤ç­‰æŠ€è¡“åº•è˜Šã€‚ã€Šæ•¸ä½æ™‚ä»£ã€‹ç›¤é»é»ƒä»å‹³æ¼”èªªä¸­ï¼Œä¸èƒ½éŒ¯éçš„AIä¸‰å¤§é—œéµå­—ã€‚

é—œéµå­—ä¸€ï¼šNIMã€‚æ¨è«–å¾®æœå‹™ï¼Œè®“ä½ å¹¾åˆ†é˜å…§å°±å¯ç”¨AI
é»ƒä»å‹³é‡ç”³äº†AIçš„ç™¼å±•æ­·ç¨‹ï¼š2012å¹´ï¼Œä¸€åå¤šå€«å¤šå¤§å­¸çš„å­¸ç”ŸAlex Krizhevskyï¼Œé‹ç”¨å…©å¼µè¼é”é¡¯å¡å’Œ120è¬å¼µåœ–ç‰‡é€²è¡ŒAIå»ºæ¨¡ï¼Œé”åˆ°éŒ¯èª¤ç‡åƒ…15%çš„æˆç¸¾ï¼Œå’Œå‰ä¸€å¹´çš„25%ç›¸æ¯”ç‚ºé£›èºå¼çš„é€²æ­¥ã€‚è¼é”ä¹Ÿé–‹å§‹ç©æ¥µä½ˆå±€AIï¼Œä¸¦æ–¼2006å¹´é–‹ç™¼å‡ºCUDAã€‚é€™æ˜¯ä¸€å¥—è¼é”æä¾›çµ¦é–‹ç™¼äººå“¡çš„ç·¨ç¨‹å·¥å…·ï¼Œå·¥ç¨‹å¸«é™¤äº†èƒ½çœä¸‹å¤§é‡æ’°å¯«ä½éšèªæ³•çš„æ™‚é–“ï¼Œé‚„èƒ½ç›´æ¥ä½¿ç”¨é«˜éšèªæ³•è«¸å¦‚C++æˆ–Javaç­‰ä¾†ç·¨å¯«æ‡‰ç”¨æ–¼é€šç”¨GPUä¸Šçš„æ¼”ç®—æ³•ï¼Œè§£æ±ºå¹³è¡Œé‹ç®—ä¸­è¤‡é›œçš„å•é¡Œã€‚ç°¡å–®ä¾†èªªï¼Œå°±æ˜¯æä¾›AIé–‹ç™¼è€…æ›´ç°¡å–®çš„å·¥å…·ã€‚

NIMç‚ºé è¨“ç·´æ¨¡å‹åŒ…ï¼Œå…§å«CUDAè»Ÿé«”ï¼Œä»¥åŠæ–‡å­—ã€èªéŸ³æˆ–ç•«é¢ç­‰æ¨¡å‹ï¼Œä½¿ç”¨æ–¹å¼å°±å¦‚ChatGPTèˆ¬è¼¸å…¥æŒ‡ä»¤å³å¯ã€‚é€™è®“é–‹ç™¼è€…èƒ½åœ¨å¹¾åˆ†é˜å…§å»ºæ§‹å¦‚Copilotæˆ–èŠå¤©æ©Ÿå™¨äººç­‰æ‡‰ç”¨ç¨‹å¼ï¼Œæˆ–ç”Ÿæˆä¸€æ®µèªå¥ã€å½±ç‰‡æˆ–åœ–ç‰‡ã€‚ç”šè‡³æ–¼ï¼Œé€éNIMé‚„èƒ½ç”¨æ–¼ç”Ÿç‰©ç§‘æŠ€ï¼ŒåŠ å¿«è—¥ç‰©æ¢ç´¢çš„é€²åº¦ã€‚

é—œéµå­—äºŒï¼šæ•¸ä½äººé¡ã€‚AIæ›´åƒçœŸäººäº†ï¼Ÿ
é»ƒä»å‹³é‚„æå‡ºã€Œæ•¸ä½äººé¡ï¼ˆDigital Humanï¼‰ã€çš„æ¦‚å¿µï¼Œè¡¨ç¤ºé€éã€ŒNVIDIA ACE NIMã€çš„æœå‹™ï¼Œæ–¼æ•™è‚²ã€è¡ŒéŠ·æˆ–æ˜¯é è·é†«ç™‚ç­‰å ´åŸŸï¼Œè¼•é¬†å»ºç«‹å°ˆå±¬çš„æ•¸ä½äººé¡ã€‚ç¾å ´å±•ç¤ºä¸‹ï¼Œæ•¸ä½äººé¡é–‹å£èªªçš„ç¥æƒ…å’Œèªæ°£ï¼Œæ ©æ ©å¦‚ç”Ÿã€‚

é—œéµå­—ä¸‰ï¼šRubinã€‚é»ƒä»å‹³é¦–æ¬¡æ­éœ²ä¸‹ä¸€ä»£GPUè·¯ç·š
åœ¨ç¡¬é«”æ–¹é¢ï¼Œè¼é”å±•ç¤ºå‡ºæ”œæ‰‹è¯ç¢©åŠå¾®æ˜Ÿæ‰€æ¨å‡ºçš„RTX AI PCï¼Œè¡¨ç¤ºå°‡æœ‰200å¤šæ¬¾ç”¢å“å•ä¸–ã€‚æ¥­å…§äººå£«é€éœ²ï¼Œè¼é”ä¹Ÿå°‡æ”œæ‰‹è¯ç™¼ç§‘ï¼Œæ¡å°ç©é›»3å¥ˆç±³è£½ç¨‹è£½ä½œArmæ¶æ§‹çš„PCæ™¶ç‰‡ï¼Œé æœŸå¹´åº•æˆ–æ˜å¹´ä¸ŠåŠé‡ç”¢ã€‚å€¼å¾—ä¸€æçš„æ˜¯ï¼Œé»ƒä»å‹³ä»Šæ—¥é¦–åº¦æ­éœ²ä¸‹ä¸€ä»£GPUå¹³å°ã€ŒRubinã€ï¼Œé æœŸå°‡æ¡ç”¨HBM4ï¼Œä¸¦æ–¼2026å¹´æ­£å¼æ¨å‡ºï¼Œ2027å¹´å‰‡å°‡é€²å…¥ã€ŒRubin Ultraã€ä¸–ä»£ï¼Œé æœŸå°‡æ¡ç”¨3å¥ˆç±³è£½ç¨‹ã€‚2025å¹´å‰‡å°‡æ¨å‡ºã€ŒBlackwell Ultraã€ï¼Œé æœŸå°‡æ¡HBM3eã€‚
"""
    if selected_summary == "Text Input":
        summary_grid = grid(1, 1, 1, vertical_align="bottom")
        summary_input = summary_grid.text_area("å¯ä»¥è¼¸å…¥æ–°èæˆ–æ–‡ç« ï¼ï¼ˆå­—æ•¸è«‹æ§åˆ¶åœ¨500å­—å…§ï¼‰", article.strip(), height=230)
        if summary_grid.button("Go Summary", use_container_width=True):
            with st.spinner('Reading and Summarzing...'):
                summary_result = summary(summary_input)
                tokens = summary_result.split()
                container = summary_grid.empty()
                for index in range(len(tokens) + 1):
                    curr_full_text = " ".join(tokens[:index])
                    container.markdown(curr_full_text)
                    time.sleep(1 / 10)

if selected == "Chat Bot":
    st.header(':rainbow[é›²ç«¯é‹ç®—æœå‹™_ç¬¬å…­çµ„_ChatBot]')

    selected_bot = option_menu(
        menu_title=None,
        options=["Memory", "Single Round"],
        icons=["memory", "chat-dots-fill"],
        menu_icon="cast",
        default_index=0,
        orientation="horizontal",
        styles={
            "container": {"padding": "0!important", "background-color": background_color},
            "icon": {"color": "orange", "font-size": "25px"},
            "nav-link": {
                "font-size": "25px",
                "text-align": "left",
                "margin": "0px",
                "--hover-color": "#eee",
            },
            "nav-link-selected": {"background-color": "#6F00D2"},
        },
    )

    if selected_bot == "Memory":
        with st.chat_message("assistant"):
            st.markdown(":orange[æ‚¨å¥½ï¼Œæˆ‘å¯ä»¥åœ¨æˆ‘èƒ½åŠ›ç¯„åœå…§ç›¡å¯èƒ½å¹«åŠ©æ‚¨ï¼ğŸ˜]")
        # Initialize chat history
        if "messages" not in st.session_state:
            st.session_state.messages = []

        # Display chat messages from history on app rerun
        for message in st.session_state.messages:
            with st.chat_message(message["role"]):
                st.markdown(message["content"])

        # React to user input
        if prompt := st.chat_input("Chat With Llama3 Bot"):
            # Display user message in chat message container
            st.chat_message("user").markdown(prompt)
            # Add user message to chat history
            st.session_state.messages.append({"role": "user", "content": prompt})

            response = memory_chat(prompt)
            # Display assistant response in chat message container
            with st.chat_message("assistant"):
                st.markdown(response)
            # Add assistant response to chat history
            st.session_state.messages.append({"role": "assistant", "content": response})

    if selected_bot == "Single Round":
        with st.chat_message("assistant"):
            st.markdown(":orange[æ‚¨å¥½ï¼Œæˆ‘å¯ä»¥åœ¨æˆ‘èƒ½åŠ›ç¯„åœå…§ç›¡å¯èƒ½å¹«åŠ©æ‚¨ï¼ğŸ˜]")
        # Initialize chat history
        if "messages_single" not in st.session_state:
            st.session_state.messages_single = []

        # Display chat messages from history on app rerun
        for message in st.session_state.messages_single:
            with st.chat_message(message["role"]):
                st.markdown(message["content"])

        # React to user input
        if prompt := st.chat_input("Chat With Llama3 Bot"):
            # Display user message in chat message container
            st.chat_message("user").markdown(prompt)
            # Add user message to chat history
            st.session_state.messages_single.append({"role": "user", "content": prompt})

            response = single_chat(prompt)
            # Display assistant response in chat message container
            with st.chat_message("assistant"):
                st.markdown(response)
            # Add assistant response to chat history
            st.session_state.messages_single.append({"role": "assistant", "content": response})

if selected == "Image Vision":
    st.header(':rainbow[é›²ç«¯é‹ç®—æœå‹™_ç¬¬å…­çµ„_Image Vision]')

    selected_image = option_menu(
        menu_title=None,
        options=["Image DataBase", "Upload"],
        icons=["file-richtext-fill", "cloud-upload-fill"],
        menu_icon="cast",
        default_index=0,
        orientation="horizontal",
        styles={
            "container": {"padding": "0!important", "background-color": background_color},
            "icon": {"color": "orange", "font-size": "25px"},
            "nav-link": {
                "font-size": "25px",
                "text-align": "left",
                "margin": "0px",
                "--hover-color": "#eee",
            },
            "nav-link-selected": {"background-color": "#6F00D2"},
        },
    )

    if selected_image == "Image DataBase":
        blob_list = get_blob_list("image")
        vision_grid = grid([1,1],[1,1],1, vertical_align="center")
        image_file = vision_grid.selectbox("è«‹é¸æ“‡åœ–ç‰‡", blob_list)
        vision_input_lan = vision_grid.selectbox("é¸æ“‡è¼¸å‡ºèªè¨€ï¼š", ["ç¹é«”ä¸­æ–‡ (zh-hant)", "è‹±æ–‡ (en)", "æ—¥æ–‡ (ja)", "è¥¿ç­ç‰™æ–‡ (es)"])
        url = f"https://storage09170285.blob.core.windows.net/image/{image_file}"
        vision_grid.image(url, width=300)
        if "default_vision_data" not in st.session_state:
            st.session_state["default_vision_data"] = ""
        vision_result = vision_grid.text_area("è¾¨è­˜çµæœï¼š", value=st.session_state["default_vision_data"], height=50)

        if vision_grid.button("Recognize", use_container_width=True, help="Press the Bottom to Recognize"):
            with st.spinner('Recognizing...'):
                recognize_result, recognize_score = recognizer_azure(url, language[vision_input_lan], 1)
                st.session_state["default_vision_data"] = recognize_result
                st.rerun()

    if selected_image == "Upload":
        vision_grid = grid(1,1,[1,1], vertical_align="center")
        vision_input_lan = vision_grid.selectbox("é¸æ“‡è¼¸å‡ºèªè¨€ï¼š", ["ç¹é«”ä¸­æ–‡ (zh-hant)", "è‹±æ–‡ (en)", "æ—¥æ–‡ (ja)", "è¥¿ç­ç‰™æ–‡ (es)"])

        uploaded_file = vision_grid.file_uploader("Choose a image file!")
        if uploaded_file is not None:
            vision_grid.image(uploaded_file, width=300)
            if "default_vision" not in st.session_state:
                st.session_state["default_vision"] = ""
            vision_result = vision_grid.text_area("è¾¨è­˜çµæœï¼š", value=st.session_state["default_vision"], height=50)
            url = f"https://storage09170285.blob.core.windows.net/image/{uploaded_file.name}"

            # Upload the file to Azure Storage on button click
            if st.button("Upload to Azure Storage and Recognize", use_container_width=True):
                try:
                    with st.spinner('Uploading...'):
                        upload_to_azure_storage(uploaded_file)
                        st.success("File uploaded to Azure Storage!", icon="âœ…")
                except:
                    st.error("Error uploading file to Azure Storage, because the file is already exist!")
            
                finally:
                    with st.spinner('Recognizing...'):
                        time.sleep(5)
                        recognize_result, recognize_score = recognizer_azure(url, language[vision_input_lan], 1)
                        st.session_state["default_vision"] = recognize_result
                        st.session_state["default_score"] = round(recognize_score*100, 2)
                        st.rerun()
